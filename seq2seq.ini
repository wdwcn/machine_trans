[strings]
# 源语言输入文件。
SRC_TRAIN_DATA = data_corpus/train.en
# 目标语言输入文件。
TRG_TRAIN_DATA = data_corpus/train.zh
# checkpoint保存路径。
MODEL_PATH = model/seq2seq_ckpt
# 读取checkpoint的路径。9000表示是训练程序在第9000步保存的checkpoint。
CHECKPOINT_PATH = model/seq2seq_ckpt-9000
# 词汇表文件
SRC_VOCAB = data_corpus/en.vocab
TRG_VOCAB = data_corpus/zh.vocab

# 在Softmax层和词向量层之间共享参数。
SHARE_EMB_AND_SOFTMAX = True

[ints]
# LSTM的隐藏层规模。
HIDDEN_SIZE = 1024
# 深层循环神经网络中LSTM结构的层数。
NUM_LAYERS = 2
# 源语言词汇表大小。
SRC_VOCAB_SIZE = 10000
# 目标语言词汇表大小。
TRG_VOCAB_SIZE = 4000
# 训练数据batch的大小
BATCH_SIZE = 100
# 使用训练数据的轮数
NUM_EPOCH = 5
# 用于控制梯度膨胀的梯度大小上限。
MAX_GRAD_NORM = 5
# 限定句子的最大单词数量。
MAX_LEN = 50
# 目标语言词汇表中<sos>的ID。
SOS_ID  = 1
EOS_ID = 2
[floats]
# 节点不被dropout的概率。
KEEP_PROB = 0.8